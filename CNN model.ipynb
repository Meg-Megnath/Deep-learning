{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test,y_test) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_train (50000, 32, 32, 3)\n",
      "shape of X_test (10000, 32, 32, 3)\n",
      "shape of y_train (50000, 1)\n",
      "shape of y_test (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print('shape of X_train', X_train.shape)\n",
    "print('shape of X_test', X_test.shape)\n",
    "print('shape of y_train', y_train.shape)\n",
    "print('shape of y_test', y_test.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_train is a 2D array, for our classification having 1D array is good enough. so we will convert this to now 1D arra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(-1,)\n",
    "y_test = y_test.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y_train (50000,)\n",
      "shape of y_test (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('shape of y_train', y_train.shape)\n",
    "print('shape of y_test', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "we now need to normalize the data, since normalizing the images in deep learning will produce very good results.\n",
    "Normalizing means we are bringing all the values in the data into a common scale 0-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Model with 1 layer of CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,Dense,Flatten,Activation,MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = models.Sequential([\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 26s 15ms/step - loss: 1.5189 - accuracy: 0.4558\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 1.2054 - accuracy: 0.5772\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 1.1101 - accuracy: 0.6124\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 1.0466 - accuracy: 0.6350\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 1.0049 - accuracy: 0.6497\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 0.9605 - accuracy: 0.6644\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 0.9262 - accuracy: 0.6769\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 0.8913 - accuracy: 0.6913\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.8653 - accuracy: 0.6996\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 24s 16ms/step - loss: 0.8404 - accuracy: 0.70720s - loss: 0.8400 - accuracy: 0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2210d781250>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 1.0472 - accuracy: 0.6413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.047207236289978, 0.6413000226020813]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "by implementing only one CNN layer we have achieved 64% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "what is convolution layer?\n",
    "The image shows what a convolution is. We take a filter/kernel(3×3 matrix) and apply it to the input image to get the convolved feature. This convolved feature is passed on to the next layer.\n",
    "\n",
    "what is pooling layer?\n",
    "Similar to the Convolutional Layer, the Pooling layer is responsible for reducing the spatial size of the Convolved Feature. This is to decrease the computational power required to process the data by reducing the dimensions. There are two types of pooling average pooling and max pooling. \n",
    "\n",
    "what is flatten?\n",
    "Flattening is converting the data into a 1-dimensional array for inputting it to the next layer. We flatten the output of the convolutional layers to create a single long feature vector. And it is connected to the final classification model, which is called a fully-connected layer.\n",
    "\n",
    "what is dense network?\n",
    "The dense layer is a fully connected layer, meaning all the neurons in a layer are connected to those in the next lay. A densely connected layer provides learning features from all the combinations of the features of the previous layer, whereas a convolutional layer relies on consistent features with a small repetitive field.\n",
    "\n",
    "what is relu activation?\n",
    "Using relu activation to bring Non - Linearity in the Model.\n",
    "relu activation will take a feature map of the image and convert neg values to zero.\n",
    "\n",
    "what is softmax activation?\n",
    "Softmax is an activation function that scales numbers/Logits into probabilities. The output of a softmax is a vector (Say v) with probabilities of each possible outcome. The probabilities in vector v sums to one for all possible outcomes or classes. \n",
    "\n",
    "understanding model.compile\n",
    "Compiling the model takes three parameters: optimizer, loss and metrics. The optimizer controls the learning rate. We will be using ‘adam’. We will use ‘sparse_categorical_crossentropy’ for our loss function. A lower score indicates that the model is performing better. Then we will use the ‘accuracy’ metric to see the accuracy score on the validation set when we train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Model with 2 layer of CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,Dense,Flatten,Activation,MaxPooling2D,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2 = models.Sequential([\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(filters = 70, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(38, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 37s 23ms/step - loss: 1.5629 - accuracy: 0.4338\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 1.1651 - accuracy: 0.5915\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.0347 - accuracy: 0.6381\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 0.9529 - accuracy: 0.6677\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 0.8922 - accuracy: 0.6909\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 0.8508 - accuracy: 0.7040\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 37s 24ms/step - loss: 0.8047 - accuracy: 0.72131s - loss: 0.8047 - accuracy:  - ETA: 1s - loss: 0.8043 - accuracy: 0.72 -\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 37s 24ms/step - loss: 0.7734 - accuracy: 0.7317\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.7471 - accuracy: 0.7410\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 35s 22ms/step - loss: 0.7174 - accuracy: 0.7513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2210bfa9700>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn2.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 0.9025 - accuracy: 0.6924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9024766683578491, 0.6923999786376953]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn2.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "By implementing two CNN layer we have achieved 69% accuracy a major improvement over 1st model's 64% accuracy. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "we can keep adding layers to improve the model.\n",
    "\n",
    "                    or\n",
    "\n",
    "we can increase the epochs to improve the model.\n",
    "[i personally wont suggest using this method at this stage of model building process \n",
    " as it need some hundreds of epochs to improve the model accuray]  \n",
    "\n",
    "                    or\n",
    "\n",
    "we can tune the model by adding parameters to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Layer CNN Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "what is dropout layer?\n",
    "Drop out means we gonna drop some of the unactivated neural units  \n",
    "from our network, which forces the next layer to learn the patterns again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn4 = models.Sequential([\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    layers.Conv2D(filters = 70, kernel_size=(3, 3),padding=\"same\", activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    layers.Conv2D(filters = 90, kernel_size=(3, 3),padding=\"same\", activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(160, activation='relu'),\n",
    "    layers.Dense(80, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 16, 16, 70)        20230     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 8, 8, 70)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 8, 8, 70)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 90)          56790     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 4, 4, 90)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4, 4, 90)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1440)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 160)               230560    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 80)                12880     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                810       \n",
      "=================================================================\n",
      "Total params: 322,166\n",
      "Trainable params: 322,166\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1563/1563 [==============================] - 49s 30ms/step - loss: 1.5622 - accuracy: 0.4278\n",
      "Epoch 2/15\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.1871 - accuracy: 0.5767\n",
      "Epoch 3/15\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.0323 - accuracy: 0.63370s - loss: 1.0322 - accuracy: 0.\n",
      "Epoch 4/15\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.9405 - accuracy: 0.6685\n",
      "Epoch 5/15\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.8769 - accuracy: 0.6929\n",
      "Epoch 6/15\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 0.8271 - accuracy: 0.7069\n",
      "Epoch 7/15\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.7887 - accuracy: 0.7228\n",
      "Epoch 8/15\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.7594 - accuracy: 0.7302\n",
      "Epoch 9/15\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.7306 - accuracy: 0.7420\n",
      "Epoch 10/15\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 0.7058 - accuracy: 0.7505\n",
      "Epoch 11/15\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.6825 - accuracy: 0.7580\n",
      "Epoch 12/15\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.6639 - accuracy: 0.7671\n",
      "Epoch 13/15\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 0.6445 - accuracy: 0.77100s -\n",
      "Epoch 14/15\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.6316 - accuracy: 0.7771\n",
      "Epoch 15/15\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.6110 - accuracy: 0.7855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2210f145310>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn4.fit(X_train, y_train, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 0.7192 - accuracy: 0.7526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7192289233207703, 0.7526000142097473]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn4.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cnn4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 8, 8, 0, 6]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_classes = [np.argmax(i) for i in y_pred]\n",
    "y_classes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 8, 8, 0, 6], dtype=uint8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
